{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO//ruQQUxlR8xkDf5KB+Ex",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoonZeee/textminer-pro/blob/main/textminer_pro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# textminer-pro: 텍스트 전처리 & 분석 패키지\n",
        "## 이지훈\n",
        "\n",
        "이 프로젝트는 텍스트 데이터를 보다 효과적으로 처리하고 분석하기 위해 만든 Python 기반 경량 패키지입니다.  \n",
        "NLTK, scikit-learn, Sumy, langdetect 등을 활용하여 다음 기능을 제공합니다:\n",
        "\n",
        "- 불용어 제거 (`remove_stopwords`)\n",
        "- 키워드 추출 (`extract_keywords`)\n",
        "- 텍스트 요약 (`summarize_text`)\n",
        "- 언어 감지 (`detect_language`)\n",
        "\n"
      ],
      "metadata": {
        "id": "gUAkRkI82e_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 디렉터리 생성"
      ],
      "metadata": {
        "id": "pYmycKESidk5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jvH1x3TOh7vX"
      },
      "outputs": [],
      "source": [
        "!mkdir -p textminer_pro/textminer\n",
        "!mkdir -p textminer_pro/tests\n",
        "!mkdir -p textminer_pro/.github/workflows\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n",
        "!pip install sumy\n",
        "!pip install twine"
      ],
      "metadata": {
        "id": "vPedRt3OqAVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cleaner.py"
      ],
      "metadata": {
        "id": "iM0xdmQaiynv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile textminer_pro/textminer/cleaner.py\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "NLTK_PATH = \"/content/nltk_data\"\n",
        "nltk.data.path.append(NLTK_PATH)\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def remove_stopwords(text: str) -> str:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text)\n",
        "    filtered = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered)\n",
        "\n",
        "def extract_keywords(text: str, top_n=5) -> list:\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = vectorizer.fit_transform([text])\n",
        "    scores = zip(vectorizer.get_feature_names_out(), tfidf_matrix.toarray()[0])\n",
        "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
        "    keywords = [word for word, score in sorted_scores[:top_n]]\n",
        "    return keywords\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFfwb57piyKW",
        "outputId": "a788d6e2-70fa-459a-b099-176484bfca5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing textminer_pro/textminer/cleaner.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cleaner.py 테스트코드"
      ],
      "metadata": {
        "id": "OMw-dm7JxdR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile textminer_pro/tests/test_cleaner.py\n",
        "import sys\n",
        "sys.path.append('/content/textminer_pro')\n",
        "import os\n",
        "import nltk\n",
        "from textminer import remove_stopwords, extract_keywords\n",
        "\n",
        "\n",
        "NLTK_PATH = \"/content/nltk_data\"\n",
        "os.environ[\"NLTK_DATA\"] = NLTK_PATH\n",
        "nltk.data.path.append(NLTK_PATH)\n",
        "\n",
        "\n",
        "nltk.download('punkt', download_dir=NLTK_PATH)\n",
        "nltk.download('punkt_tab', download_dir=NLTK_PATH)\n",
        "nltk.download('stopwords', download_dir=NLTK_PATH)\n",
        "\n",
        "text = \"This is a test sentence with simple words.\"\n",
        "print(\"Stopword 제거 결과:\")\n",
        "print(remove_stopwords(text))\n",
        "\n",
        "text2 = \"Machine learning is fun and powerful.\"\n",
        "print(\"키워드 추출 결과:\")\n",
        "print(extract_keywords(text2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FfjfaRHi8Zj",
        "outputId": "7d031b2f-6b4f-4ad8-b463-19e3e285b56b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing textminer_pro/tests/test_cleaner.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## summarizer.py"
      ],
      "metadata": {
        "id": "-9l8xLM7qEAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile textminer_pro/textminer/summarizer.py\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lsa import LsaSummarizer\n",
        "\n",
        "def summarize_text(text: str, num_sentences=2) -> str:\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
        "    summarizer = LsaSummarizer()\n",
        "    summary = summarizer(parser.document, num_sentences)\n",
        "    return \" \".join(str(sentence) for sentence in summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKfzaptMoKrz",
        "outputId": "9cf7e2d6-7ab5-4207-c941-5e4b3c2a7f0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing textminer_pro/textminer/summarizer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## detector.py"
      ],
      "metadata": {
        "id": "kZpie_0NxAGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile textminer_pro/textminer/detector.py\n",
        "from langdetect import detect\n",
        "\n",
        "def detect_language(text: str) -> str:\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except:\n",
        "        return \"언어를 감지할 수 없습니다\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R992idzqKUv",
        "outputId": "974eddfd-6388-4032-d8e5-9228b8a7b302"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing textminer_pro/textminer/detector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## init.py"
      ],
      "metadata": {
        "id": "dgnFsO0t0ygK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile textminer_pro/textminer/__init__.py\n",
        "from .cleaner import remove_stopwords, extract_keywords\n",
        "from .summarizer import summarize_text\n",
        "from .detector import detect_language"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjvKUaz5qTYt",
        "outputId": "cf04256f-6d47-4751-8eef-0e2fb8953493"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing textminer_pro/textminer/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## detector.py 테스트코드"
      ],
      "metadata": {
        "id": "PjhYo04oxgx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile textminer_pro/tests/test_detector.py\n",
        "import sys\n",
        "sys.path.append('/content/textminer_pro')\n",
        "from textminer import detect_language\n",
        "\n",
        "text1 = \"This is an English sentence.\"\n",
        "text2 = \"이 문장은 한국어입니다.\"\n",
        "\n",
        "print(\"English 감지 결과:\", detect_language(text1))\n",
        "print(\"Korean 감지 결과:\", detect_language(text2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7u4NmLDoMkU",
        "outputId": "3bd675b0-592f-465b-f8b3-c258ae1e008a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing textminer_pro/tests/test_detector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 테스트코드 실행"
      ],
      "metadata": {
        "id": "jnYgQ68-xlUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 textminer_pro/tests/test_cleaner.py\n",
        "!python3 textminer_pro/tests/test_detector.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CVt9rVju7o5",
        "outputId": "548bc3c6-33d6-4c6f-bd66-7ffcd0a4d126"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /content/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /content/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Stopword 제거 결과:\n",
            "test sentence simple words .\n",
            "키워드 추출 결과:\n",
            "['fun', 'learning', 'machine', 'powerful']\n",
            "English 감지 결과: en\n",
            "Korean 감지 결과: ko\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile textminer_pro/setup.py\n",
        "from setuptools import setup, find_packages\n",
        "\n",
        "setup(\n",
        "    name='textminer-pro-jihoonLee',\n",
        "    version='0.1.0',\n",
        "    packages=find_packages(),\n",
        "    install_requires=[\n",
        "        'nltk',\n",
        "        'scikit-learn',\n",
        "        'sumy',\n",
        "        'langdetect'\n",
        "    ],\n",
        "    author='Jihoon Lee',\n",
        "    author_email='dlwlgns7540@naver.com',\n",
        "    description='A simple text mining package with stopword removal, keyword extraction, summarization, and language detection.',\n",
        "    long_description=open('README.md').read(),\n",
        "    long_description_content_type='text/markdown',\n",
        "    url='https://github.com/hoonZeee/Oss_2025/tree/main/pypi',\n",
        "    classifiers=[\n",
        "        'Programming Language :: Python :: 3',\n",
        "        'License :: OSI Approved :: MIT License',\n",
        "    ],\n",
        "    python_requires='>=3.7',\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppWUVE_JqkJp",
        "outputId": "244f5852-c718-4454-e9d2-3308d245e54b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing textminer_pro/setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd textminer_pro\n",
        "!python setup.py sdist bdist_wheel"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Owh6uoHHrODC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /root/.pypirc\n",
        "[distutils]\n",
        "index-servers =\n",
        "    pypi\n",
        "\n",
        "[pypi]\n",
        "repository: https://upload.pypi.org/legacy/\n",
        "username: __token__\n",
        "password: 보안상 삭제합니다.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZKKTXr9sav3",
        "outputId": "c75b6e4e-e92c-4215-d2fb-c4b4b0111c3c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /root/.pypirc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!twine upload dist/*\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzeUYxUvrlle",
        "outputId": "fcbe8fda-500a-410f-f3ad-e5639ab2b191"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading distributions to https://upload.pypi.org/legacy/\n",
            "Uploading textminer_pro_jihoonLee-0.1.0-py3-none-any.whl\n",
            "\u001b[2K\u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 kB\u001b[0m • \u001b[33m00:00\u001b[0m • \u001b[31m?\u001b[0m\n",
            "\u001b[?25hUploading textminer_pro_jihoonlee-0.1.0.tar.gz\n",
            "\u001b[2K\u001b[35m100%\u001b[0m \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 kB\u001b[0m • \u001b[33m00:00\u001b[0m • \u001b[31m?\u001b[0m\n",
            "\u001b[?25h\n",
            "\u001b[32mView at:\u001b[0m\n",
            "https://pypi.org/project/textminer-pro-jihoonLee/0.1.0/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 최종 확인"
      ],
      "metadata": {
        "id": "VG9lY8ki2bHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -i https://test.pypi.org/simple/ textminer-pro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0gohWv7DskXH",
        "outputId": "538c9b2c-954f-412a-ecf1-973d1a7f9bec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://test.pypi.org/simple/\n",
            "Collecting textminer-pro\n",
            "  Downloading https://test-files.pythonhosted.org/packages/09/09/fd23a3838a48eb5f23444f38729abdd69b6516317b49adaf0b6300a85185/textminer_pro-0.1.0-py3-none-any.whl.metadata (770 bytes)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from textminer-pro) (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from textminer-pro) (1.6.1)\n",
            "Requirement already satisfied: sumy in /usr/local/lib/python3.11/dist-packages (from textminer-pro) (0.11.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (from textminer-pro) (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect->textminer-pro) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->textminer-pro) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->textminer-pro) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->textminer-pro) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->textminer-pro) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->textminer-pro) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->textminer-pro) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->textminer-pro) (3.6.0)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from sumy->textminer-pro) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.11/dist-packages (from sumy->textminer-pro) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from sumy->textminer-pro) (2.32.3)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.11/dist-packages (from sumy->textminer-pro) (24.6.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy->textminer-pro) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.11/dist-packages (from breadability>=0.1.20->sumy->textminer-pro) (5.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy->textminer-pro) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy->textminer-pro) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy->textminer-pro) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.7.0->sumy->textminer-pro) (2025.4.26)\n",
            "Downloading https://test-files.pythonhosted.org/packages/09/09/fd23a3838a48eb5f23444f38729abdd69b6516317b49adaf0b6300a85185/textminer_pro-0.1.0-py3-none-any.whl (3.0 kB)\n",
            "Installing collected packages: textminer-pro\n",
            "Successfully installed textminer-pro-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textminer import remove_stopwords, extract_keywords, summarize_text, detect_language\n",
        "\n",
        "text = \"The OSS assignment is fun and educational, making it easier to extract key insights, summarize complex ideas, and even detect the language used!\"\n",
        "text2 = \"OSS 과제는 재미있고 유익해서, 텍스트 요약이나 키워드 추출, 언어 감지까지 쉽게 해볼 수 있다.\"\n",
        "\n",
        "\n",
        "print(remove_stopwords(text))\n",
        "print(extract_keywords(text))\n",
        "print(summarize_text(text))\n",
        "print(detect_language(text))\n",
        "\n",
        "print(remove_stopwords(text2))\n",
        "print(extract_keywords(text2))\n",
        "print(summarize_text(text2))\n",
        "print(detect_language(text2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfXoKicOsuY_",
        "outputId": "fb2ee270-981a-494f-8498-9b0c799f652e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OSS assignment fun educational , making easier extract key insights , summarize complex ideas , even detect language used !\n",
            "['assignment', 'complex', 'detect', 'easier', 'educational']\n",
            "The OSS assignment is fun and educational, making it easier to extract key insights, summarize complex ideas, and even detect the language used!\n",
            "en\n",
            "OSS 과제는 재미있고 유익해서 , 텍스트 요약이나 키워드 추출 , 언어 감지까지 쉽게 해볼 수 있다 .\n",
            "['oss', '감지까지', '과제는', '쉽게', '언어']\n",
            "\n",
            "ko\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Git 연동"
      ],
      "metadata": {
        "id": "wmL4xjok93wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "\n",
        "!git init\n",
        "!git rm -r --cached nltk_data sample_data .config"
      ],
      "metadata": {
        "id": "51EprEwN5Web"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .gitignore\n",
        "nltk_data/\n",
        "sample_data/\n",
        ".config/\n",
        "__pycache__/\n",
        "*.pyc\n",
        "*.ipynb_checkpoints\n",
        "*.egg-info/\n",
        "build/\n",
        "dist/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkP4OX0S8kl4",
        "outputId": "2ce2448f-f35a-43a5-b4aa-04c82d9df8a5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing .gitignore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 커밋 푸쉬는 보안상 생략하겠습니다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DZae5m0K8pCr",
        "outputId": "d18dd739-0b47-4414-b512-5ac11a34d77b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D\t.config/.last_opt_in_prompt.yaml\n",
            "D\t.config/.last_survey_prompt.yaml\n",
            "D\t.config/.last_update_check.json\n",
            "D\t.config/active_config\n",
            "D\t.config/config_sentinel\n",
            "D\t.config/configurations/config_default\n",
            "D\t.config/default_configs.db\n",
            "D\t.config/gce\n",
            "D\t.config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db\n",
            "D\t.config/logs/2025.06.11/13.36.48.453813.log\n",
            "D\t.config/logs/2025.06.11/13.37.08.919149.log\n",
            "D\t.config/logs/2025.06.11/13.37.17.609931.log\n",
            "D\t.config/logs/2025.06.11/13.37.18.763091.log\n",
            "D\t.config/logs/2025.06.11/13.37.27.125319.log\n",
            "D\t.config/logs/2025.06.11/13.37.27.755669.log\n",
            "D\tnltk_data/corpora/stopwords.zip\n",
            "D\tnltk_data/corpora/stopwords/README\n",
            "D\tnltk_data/corpora/stopwords/albanian\n",
            "D\tnltk_data/corpora/stopwords/arabic\n",
            "D\tnltk_data/corpora/stopwords/azerbaijani\n",
            "D\tnltk_data/corpora/stopwords/basque\n",
            "D\tnltk_data/corpora/stopwords/belarusian\n",
            "D\tnltk_data/corpora/stopwords/bengali\n",
            "D\tnltk_data/corpora/stopwords/catalan\n",
            "D\tnltk_data/corpora/stopwords/chinese\n",
            "D\tnltk_data/corpora/stopwords/danish\n",
            "D\tnltk_data/corpora/stopwords/dutch\n",
            "D\tnltk_data/corpora/stopwords/english\n",
            "D\tnltk_data/corpora/stopwords/finnish\n",
            "D\tnltk_data/corpora/stopwords/french\n",
            "D\tnltk_data/corpora/stopwords/german\n",
            "D\tnltk_data/corpora/stopwords/greek\n",
            "D\tnltk_data/corpora/stopwords/hebrew\n",
            "D\tnltk_data/corpora/stopwords/hinglish\n",
            "D\tnltk_data/corpora/stopwords/hungarian\n",
            "D\tnltk_data/corpora/stopwords/indonesian\n",
            "D\tnltk_data/corpora/stopwords/italian\n",
            "D\tnltk_data/corpora/stopwords/kazakh\n",
            "D\tnltk_data/corpora/stopwords/nepali\n",
            "D\tnltk_data/corpora/stopwords/norwegian\n",
            "D\tnltk_data/corpora/stopwords/portuguese\n",
            "D\tnltk_data/corpora/stopwords/romanian\n",
            "D\tnltk_data/corpora/stopwords/russian\n",
            "D\tnltk_data/corpora/stopwords/slovene\n",
            "D\tnltk_data/corpora/stopwords/spanish\n",
            "D\tnltk_data/corpora/stopwords/swedish\n",
            "D\tnltk_data/corpora/stopwords/tajik\n",
            "D\tnltk_data/corpora/stopwords/tamil\n",
            "D\tnltk_data/corpora/stopwords/turkish\n",
            "D\tnltk_data/tokenizers/punkt.zip\n",
            "D\tnltk_data/tokenizers/punkt/.DS_Store\n",
            "D\tnltk_data/tokenizers/punkt/PY3/README\n",
            "D\tnltk_data/tokenizers/punkt/PY3/czech.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/danish.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/dutch.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/english.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/estonian.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/finnish.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/french.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/german.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/greek.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/italian.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/malayalam.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/norwegian.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/polish.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/portuguese.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/russian.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/slovene.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/spanish.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/swedish.pickle\n",
            "D\tnltk_data/tokenizers/punkt/PY3/turkish.pickle\n",
            "D\tnltk_data/tokenizers/punkt/README\n",
            "D\tnltk_data/tokenizers/punkt/czech.pickle\n",
            "D\tnltk_data/tokenizers/punkt/danish.pickle\n",
            "D\tnltk_data/tokenizers/punkt/dutch.pickle\n",
            "D\tnltk_data/tokenizers/punkt/english.pickle\n",
            "D\tnltk_data/tokenizers/punkt/estonian.pickle\n",
            "D\tnltk_data/tokenizers/punkt/finnish.pickle\n",
            "D\tnltk_data/tokenizers/punkt/french.pickle\n",
            "D\tnltk_data/tokenizers/punkt/german.pickle\n",
            "D\tnltk_data/tokenizers/punkt/greek.pickle\n",
            "D\tnltk_data/tokenizers/punkt/italian.pickle\n",
            "D\tnltk_data/tokenizers/punkt/malayalam.pickle\n",
            "D\tnltk_data/tokenizers/punkt/norwegian.pickle\n",
            "D\tnltk_data/tokenizers/punkt/polish.pickle\n",
            "D\tnltk_data/tokenizers/punkt/portuguese.pickle\n",
            "D\tnltk_data/tokenizers/punkt/russian.pickle\n",
            "D\tnltk_data/tokenizers/punkt/slovene.pickle\n",
            "D\tnltk_data/tokenizers/punkt/spanish.pickle\n",
            "D\tnltk_data/tokenizers/punkt/swedish.pickle\n",
            "D\tnltk_data/tokenizers/punkt/turkish.pickle\n",
            "D\tnltk_data/tokenizers/punkt_tab.zip\n",
            "D\tnltk_data/tokenizers/punkt_tab/README\n",
            "D\tnltk_data/tokenizers/punkt_tab/czech/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/czech/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/czech/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/czech/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/danish/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/danish/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/danish/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/danish/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/dutch/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/dutch/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/dutch/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/dutch/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/english/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/english/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/english/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/english/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/estonian/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/estonian/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/estonian/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/estonian/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/finnish/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/finnish/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/finnish/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/finnish/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/french/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/french/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/french/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/french/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/german/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/german/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/german/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/german/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/greek/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/greek/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/greek/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/greek/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/italian/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/italian/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/italian/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/italian/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/malayalam/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/malayalam/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/malayalam/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/malayalam/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/norwegian/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/norwegian/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/norwegian/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/norwegian/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/polish/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/polish/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/polish/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/polish/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/portuguese/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/portuguese/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/portuguese/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/portuguese/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/russian/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/russian/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/russian/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/russian/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/slovene/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/slovene/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/slovene/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/slovene/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/spanish/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/spanish/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/spanish/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/spanish/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/swedish/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/swedish/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/swedish/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/swedish/sent_starters.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/turkish/abbrev_types.txt\n",
            "D\tnltk_data/tokenizers/punkt_tab/turkish/collocations.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/turkish/ortho_context.tab\n",
            "D\tnltk_data/tokenizers/punkt_tab/turkish/sent_starters.txt\n",
            "D\tsample_data/README.md\n",
            "D\tsample_data/anscombe.json\n",
            "D\tsample_data/california_housing_test.csv\n",
            "D\tsample_data/california_housing_train.csv\n",
            "D\tsample_data/mnist_test.csv\n",
            "D\tsample_data/mnist_train_small.csv\n",
            "Reset branch 'main'\n",
            "fatal: pathspec 'README.md' did not match any files\n",
            "[main e68a914] clean commit\n",
            " 175 files changed, 3181294 deletions(-)\n",
            " delete mode 100644 .config/.last_opt_in_prompt.yaml\n",
            " delete mode 100644 .config/.last_survey_prompt.yaml\n",
            " delete mode 100644 .config/.last_update_check.json\n",
            " delete mode 100644 .config/active_config\n",
            " delete mode 100644 .config/config_sentinel\n",
            " delete mode 100644 .config/configurations/config_default\n",
            " delete mode 100644 .config/default_configs.db\n",
            " delete mode 100644 .config/gce\n",
            " delete mode 100644 .config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db\n",
            " delete mode 100644 .config/logs/2025.06.11/13.36.48.453813.log\n",
            " delete mode 100644 .config/logs/2025.06.11/13.37.08.919149.log\n",
            " delete mode 100644 .config/logs/2025.06.11/13.37.17.609931.log\n",
            " delete mode 100644 .config/logs/2025.06.11/13.37.18.763091.log\n",
            " delete mode 100644 .config/logs/2025.06.11/13.37.27.125319.log\n",
            " delete mode 100644 .config/logs/2025.06.11/13.37.27.755669.log\n",
            " delete mode 100644 nltk_data/corpora/stopwords.zip\n",
            " delete mode 100644 nltk_data/corpora/stopwords/README\n",
            " delete mode 100644 nltk_data/corpora/stopwords/albanian\n",
            " delete mode 100644 nltk_data/corpora/stopwords/arabic\n",
            " delete mode 100644 nltk_data/corpora/stopwords/azerbaijani\n",
            " delete mode 100644 nltk_data/corpora/stopwords/basque\n",
            " delete mode 100644 nltk_data/corpora/stopwords/belarusian\n",
            " delete mode 100644 nltk_data/corpora/stopwords/bengali\n",
            " delete mode 100644 nltk_data/corpora/stopwords/catalan\n",
            " delete mode 100644 nltk_data/corpora/stopwords/chinese\n",
            " delete mode 100644 nltk_data/corpora/stopwords/danish\n",
            " delete mode 100644 nltk_data/corpora/stopwords/dutch\n",
            " delete mode 100644 nltk_data/corpora/stopwords/english\n",
            " delete mode 100644 nltk_data/corpora/stopwords/finnish\n",
            " delete mode 100644 nltk_data/corpora/stopwords/french\n",
            " delete mode 100644 nltk_data/corpora/stopwords/german\n",
            " delete mode 100644 nltk_data/corpora/stopwords/greek\n",
            " delete mode 100644 nltk_data/corpora/stopwords/hebrew\n",
            " delete mode 100644 nltk_data/corpora/stopwords/hinglish\n",
            " delete mode 100644 nltk_data/corpora/stopwords/hungarian\n",
            " delete mode 100644 nltk_data/corpora/stopwords/indonesian\n",
            " delete mode 100644 nltk_data/corpora/stopwords/italian\n",
            " delete mode 100644 nltk_data/corpora/stopwords/kazakh\n",
            " delete mode 100644 nltk_data/corpora/stopwords/nepali\n",
            " delete mode 100644 nltk_data/corpora/stopwords/norwegian\n",
            " delete mode 100644 nltk_data/corpora/stopwords/portuguese\n",
            " delete mode 100644 nltk_data/corpora/stopwords/romanian\n",
            " delete mode 100644 nltk_data/corpora/stopwords/russian\n",
            " delete mode 100644 nltk_data/corpora/stopwords/slovene\n",
            " delete mode 100644 nltk_data/corpora/stopwords/spanish\n",
            " delete mode 100644 nltk_data/corpora/stopwords/swedish\n",
            " delete mode 100644 nltk_data/corpora/stopwords/tajik\n",
            " delete mode 100644 nltk_data/corpora/stopwords/tamil\n",
            " delete mode 100644 nltk_data/corpora/stopwords/turkish\n",
            " delete mode 100644 nltk_data/tokenizers/punkt.zip\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/.DS_Store\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/README\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/czech.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/danish.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/dutch.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/english.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/estonian.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/finnish.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/french.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/german.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/greek.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/italian.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/malayalam.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/norwegian.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/polish.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/portuguese.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/russian.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/slovene.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/spanish.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/swedish.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/PY3/turkish.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/README\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/czech.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/danish.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/dutch.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/english.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/estonian.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/finnish.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/french.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/german.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/greek.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/italian.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/malayalam.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/norwegian.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/polish.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/portuguese.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/russian.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/slovene.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/spanish.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/swedish.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt/turkish.pickle\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab.zip\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/README\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/czech/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/czech/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/czech/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/czech/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/danish/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/danish/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/danish/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/danish/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/dutch/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/dutch/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/dutch/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/dutch/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/english/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/english/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/english/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/english/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/estonian/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/estonian/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/estonian/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/estonian/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/finnish/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/finnish/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/finnish/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/finnish/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/french/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/french/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/french/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/french/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/german/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/german/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/german/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/german/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/greek/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/greek/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/greek/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/greek/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/italian/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/italian/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/italian/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/italian/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/malayalam/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/malayalam/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/malayalam/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/malayalam/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/norwegian/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/norwegian/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/norwegian/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/norwegian/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/polish/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/polish/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/polish/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/polish/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/portuguese/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/portuguese/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/portuguese/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/portuguese/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/russian/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/russian/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/russian/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/russian/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/slovene/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/slovene/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/slovene/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/slovene/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/spanish/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/spanish/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/spanish/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/spanish/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/swedish/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/swedish/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/swedish/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/swedish/sent_starters.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/turkish/abbrev_types.txt\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/turkish/collocations.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/turkish/ortho_context.tab\n",
            " delete mode 100644 nltk_data/tokenizers/punkt_tab/turkish/sent_starters.txt\n",
            " delete mode 100755 sample_data/README.md\n",
            " delete mode 100755 sample_data/anscombe.json\n",
            " delete mode 100644 sample_data/california_housing_test.csv\n",
            " delete mode 100644 sample_data/california_housing_train.csv\n",
            " delete mode 100644 sample_data/mnist_test.csv\n",
            " delete mode 100644 sample_data/mnist_train_small.csv\n",
            "Enumerating objects: 3, done.\n",
            "Counting objects: 100% (3/3), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (1/1), done.\n",
            "Writing objects: 100% (2/2), 236 bytes | 236.00 KiB/s, done.\n",
            "Total 2 (delta 0), reused 0 (delta 0), pack-reused 0\n",
            "To https://github.com/hoonZeee/textminer-pro.git\n",
            "   aedfb4c..e68a914  main -> main\n"
          ]
        }
      ]
    }
  ]
}